{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38080af3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75629b3c",
   "metadata": {},
   "source": [
    "Assistant: Question 1: Supervised vs. Unsupervised Learning: Which of the following statements is true?\n",
    "\n",
    "A) In supervised learning, the model learns from labeled data.\n",
    "\n",
    "B) In unsupervised learning, the algorithm is always trained on labeled data.\n",
    "\n",
    "C) K-Nearest Neighbors is an unsupervised algorithm.\n",
    "\n",
    "D) Logistic regression does not require labeled examples.\n",
    "\n",
    "E) Supervised learning models cannot handle continuous data. \n",
    "\n",
    "User: A \n",
    "\n",
    "Assistant: Question 2: Dependent vs.Independent Variables: In a regression problem, the dependent variable is:\n",
    "\n",
    "A) the input feature the model uses to predict.\n",
    "\n",
    "B) the output value we are trying to predict.\n",
    "\n",
    "C) always one of the features in the training set.\n",
    "\n",
    "D) the same as an independent variable.\n",
    "\n",
    "E) irrelevant to model training. User: B \n",
    "\n",
    "Assistant: Question 3: Data Splits: What is the purpose of using a train-validation-test split?\n",
    "\n",
    "A) To use all data for training and avoid testing.\n",
    "\n",
    "B) To train on one set, tune hyperparameters on a second, and evaluate on a third.\n",
    "\n",
    "C) To randomly shuffle data multiple times.\n",
    "\n",
    "D) To combine all data into a single model.\n",
    "\n",
    "E) To use validation data for final deployment. User: B \n",
    "\n",
    "Assistant: Question 4: Linear Regression Residuals: In linear regression, a residual is:\n",
    "\n",
    "A) the predicted value of the model.\n",
    "\n",
    "B) the difference between the observed and predicted values.\n",
    "\n",
    "C) always positive.\n",
    "\n",
    "D) the slope of the line.\n",
    "\n",
    "E) the average of all error terms. User: B Assistant:\n",
    "\n",
    " Question 5: Linearization: Why might we transform data for linear regression?\n",
    "\n",
    "A) To make a non-linear relationship more linear.\n",
    "\n",
    "B) To increase the number of features.\n",
    "\n",
    "C) To remove the intercept term.\n",
    "\n",
    "D) To ensure variables are dependent.\n",
    "\n",
    "E) To change categorical variables into numeric. User: D \n",
    "\n",
    "Assistant: Question 6: Regression Types: Which is an example of a non-parametric regression model?\n",
    "\n",
    "A) Linear Regression\n",
    "\n",
    "B) Logistic Regression\n",
    "\n",
    "C) Random Forest Regression\n",
    "\n",
    "D) Polynomial Regression\n",
    "\n",
    "E) Ridge Regression User: C \n",
    "\n",
    "Assistant: Question 7: R-Squared vs. MSE: R-Squared in regression measures:\n",
    "\n",
    "A) the proportion of variance explained by the model.\n",
    "\n",
    "B) the average of residuals.\n",
    "\n",
    "C) the learning rate of the optimizer.\n",
    "\n",
    "D) the error on the test set only.\n",
    "\n",
    "E) none of the above. User: A \n",
    "\n",
    "Assistant: Question 8: Logistic Regression Intercept: The intercept term in logistic regression corresponds to:\n",
    "\n",
    "A) the slope of the decision boundary.\n",
    "\n",
    "B) the log-odds when all features are zero.\n",
    "\n",
    "C) the modelâ€™s accuracy.\n",
    "\n",
    "D) the cross-entropy loss.\n",
    "\n",
    "E) always zero. User: D \n",
    "\n",
    "Assistant: Question 9: Cross-Entropy: In binary classification, cross-entropy loss is used because:\n",
    "A) it penalizes wrong predictions more when the model is confident.\n",
    "B) it is the same as mean squared error.\n",
    "C) it only works for regression.\n",
    "D) it does not require probabilities.\n",
    "E) it is always negative. User: C Assistant: Question 10: KNN Hyperparameters: In K-Nearest Neighbors, increasing k generally:\n",
    "A) decreases bias and increases variance.\n",
    "B) increases bias and decreases variance.\n",
    "C) always improves accuracy.\n",
    "D) makes the model more prone to overfitting.\n",
    "E) has no effect on the model. User: B Assistant: Question 11: KNN Behavior: With a very small k (e.g. k=1), KNN tends to:\n",
    "A) Be more stable and have higher bias.\n",
    "B) Fit noise and have higher variance.\n",
    "C) Ignore the nearest neighbors.\n",
    "D) Never misclassify any point.\n",
    "E) Perform identically to k=10. User: A Assistant: Question 12: Decision Tree Leaves: A leaf node in a decision tree represents:\n",
    "A) A split point for features.\n",
    "B) A final class label or value prediction.\n",
    "C) The root of the tree.\n",
    "D) An intermediate decision rule.\n",
    "E) Always a numeric value. User: B Assistant: Question 13: Decision Tree Prediction: How does a decision tree make a prediction for a new instance?\n",
    "A) By averaging all possible outcomes.\n",
    "B) By following feature-split rules from the root to a leaf.\n",
    "C) By using the nearest neighbor in training set.\n",
    "D) By performing a linear regression on inputs.\n",
    "E) By randomly guessing. User: D Assistant: Question 14: Unsupervised Algorithm: Which of the following is unsupervised?\n",
    "A) K-Means Clustering\n",
    "B) Logistic Regression\n",
    "C) Linear Regression\n",
    "D) Decision Trees\n",
    "E) All require labels. User: A Assistant: Question 15: Regression Evaluation: Which metric is appropriate for evaluating a regression model?\n",
    "A) Accuracy\n",
    "B) F1 Score\n",
    "C) R-Squared\n",
    "D) ROC AUC\n",
    "E) Perplexity User: C Assistant: Quiz complete. You answered 10 out of 15 questions correctly. Based on your answers, you got Questions 5, 8, 9, 11, and 13 wrong. I will now create a Jupyter Notebook with exercises focusing on those topics: linearization in regression, logistic regression intercept and cross-entropy, KNN bias/variance, and decision tree predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebdf04",
   "metadata": {},
   "source": [
    "Chatgpt was used\n",
    "\n",
    "Cemil Caglar Yapici - 9081058"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
